{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-documentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.10)\n",
      "Requirement already satisfied: sklearn in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.26.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (56.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.6.1)\n"
     ]
    }
   ],
   "source": [
    "#Importing Dependencies\n",
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "raising-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from cv2 import VideoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "offensive-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic  #Holistic\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing Utitlities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "removed-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model) :\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #Color conversion\n",
    "    image.flags.writeable = False                  #Image is no longer writable \n",
    "    results = model.process(image)                 #make prediction\n",
    "    image.flags.writeable = True                   #Image is writable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) #Color conversion back\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aerial-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results) : \n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "stuck-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results) : \n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aggregate-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the webcam\n",
    "cap = VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic : \n",
    "    while cap.isOpened() :\n",
    "\n",
    "        #Reading frames\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Make detection \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_styled_landmarks(image, results)\n",
    "        #print(results)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        #break \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') : \n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "directed-plant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results.pose_landmarks.landmark).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "virgin-activation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "selected-disposal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132*4)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "german-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results) : \n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "finished-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superb-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark {\n",
       "  x: 0.5606679916381836\n",
       "  y: 0.6539683938026428\n",
       "  z: -0.032830365002155304\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5662314891815186\n",
       "  y: 0.5916970372200012\n",
       "  z: -0.07353311777114868\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5623826384544373\n",
       "  y: 0.6100836992263794\n",
       "  z: -0.03654862567782402\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5544643998146057\n",
       "  y: 0.5201610922813416\n",
       "  z: -0.06093516945838928\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5674204230308533\n",
       "  y: 0.5701866149902344\n",
       "  z: -0.07946225255727768\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5675632953643799\n",
       "  y: 0.5414620041847229\n",
       "  z: -0.07589861750602722\n",
       "}\n",
       "landmark {\n",
       "  x: 0.566236674785614\n",
       "  y: 0.47202572226524353\n",
       "  z: -0.04312750697135925\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4601966142654419\n",
       "  y: 0.4617408215999603\n",
       "  z: 0.0005335337482392788\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5669883489608765\n",
       "  y: 0.41925328969955444\n",
       "  z: -0.03730640932917595\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5683510303497314\n",
       "  y: 0.3900718688964844\n",
       "  z: -0.042235732078552246\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5701151490211487\n",
       "  y: 0.289712518453598\n",
       "  z: -0.036063361912965775\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5602093935012817\n",
       "  y: 0.6634267568588257\n",
       "  z: -0.030016208067536354\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5594360828399658\n",
       "  y: 0.6692937612533569\n",
       "  z: -0.024711763486266136\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5587829947471619\n",
       "  y: 0.6702695488929749\n",
       "  z: -0.018151819705963135\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5593929886817932\n",
       "  y: 0.6699126958847046\n",
       "  z: -0.01835157722234726\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5594330430030823\n",
       "  y: 0.6772001385688782\n",
       "  z: -0.020196475088596344\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5591158866882324\n",
       "  y: 0.6865005493164062\n",
       "  z: -0.02286612056195736\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5584349036216736\n",
       "  y: 0.6973744630813599\n",
       "  z: -0.021144678816199303\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5561223030090332\n",
       "  y: 0.7175577282905579\n",
       "  z: -0.008175058290362358\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5648880004882812\n",
       "  y: 0.6018943190574646\n",
       "  z: -0.06586796045303345\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5499454140663147\n",
       "  y: 0.5980652570724487\n",
       "  z: -0.04782964661717415\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40128475427627563\n",
       "  y: 0.3742203712463379\n",
       "  z: 0.054517537355422974\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5009119510650635\n",
       "  y: 0.4807460308074951\n",
       "  z: -0.008937298320233822\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48669809103012085\n",
       "  y: 0.48156607151031494\n",
       "  z: -0.00892208144068718\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47291144728660583\n",
       "  y: 0.4794715642929077\n",
       "  z: -0.006096277851611376\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4536149501800537\n",
       "  y: 0.4679139256477356\n",
       "  z: 0.0031311328057199717\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5129663944244385\n",
       "  y: 0.47603678703308105\n",
       "  z: -0.005963388830423355\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48380616307258606\n",
       "  y: 0.434140145778656\n",
       "  z: -0.019915563985705376\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49802637100219727\n",
       "  y: 0.43567949533462524\n",
       "  z: -0.017711317166686058\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4700528383255005\n",
       "  y: 0.43584200739860535\n",
       "  z: -0.015743287280201912\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4602162837982178\n",
       "  y: 0.4410395622253418\n",
       "  z: -0.010213849134743214\n",
       "}\n",
       "landmark {\n",
       "  x: 0.44102227687835693\n",
       "  y: 0.4784310460090637\n",
       "  z: 0.01041314285248518\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5006475448608398\n",
       "  y: 0.7501721978187561\n",
       "  z: 0.0077926465310156345\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4548688232898712\n",
       "  y: 0.4574089050292969\n",
       "  z: 0.004395415540784597\n",
       "}\n",
       "landmark {\n",
       "  x: 0.39405131340026855\n",
       "  y: 0.46309274435043335\n",
       "  z: 0.06764000654220581\n",
       "}\n",
       "landmark {\n",
       "  x: 0.42389723658561707\n",
       "  y: 0.4626573920249939\n",
       "  z: 0.022040866315364838\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48778873682022095\n",
       "  y: 0.5621740221977234\n",
       "  z: -0.015134154818952084\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5420320630073547\n",
       "  y: 0.6491663455963135\n",
       "  z: -0.03319864347577095\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5425225496292114\n",
       "  y: 0.666918158531189\n",
       "  z: -0.02427360787987709\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5218566060066223\n",
       "  y: 0.6511349678039551\n",
       "  z: -0.025916067883372307\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5081146955490112\n",
       "  y: 0.6549919843673706\n",
       "  z: -0.015684541314840317\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5276002883911133\n",
       "  y: 0.6651651859283447\n",
       "  z: -0.019860828295350075\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5156540870666504\n",
       "  y: 0.6636719107627869\n",
       "  z: -0.010629340074956417\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48923763632774353\n",
       "  y: 0.6796350479125977\n",
       "  z: 0.006792292930185795\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5539705753326416\n",
       "  y: 0.5901150703430176\n",
       "  z: -0.07333413511514664\n",
       "}\n",
       "landmark {\n",
       "  x: 0.553299069404602\n",
       "  y: 0.5692627429962158\n",
       "  z: -0.07914835214614868\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4353787899017334\n",
       "  y: 0.41193777322769165\n",
       "  z: -0.00929091963917017\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5187789797782898\n",
       "  y: 0.5143206119537354\n",
       "  z: -0.018394650891423225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5164640545845032\n",
       "  y: 0.5777875185012817\n",
       "  z: -0.04271697252988815\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5155546069145203\n",
       "  y: 0.5661121606826782\n",
       "  z: -0.03915334492921829\n",
       "}\n",
       "landmark {\n",
       "  x: 0.443085253238678\n",
       "  y: 0.5551384687423706\n",
       "  z: -0.0009424113086424768\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5541933178901672\n",
       "  y: 0.5426081418991089\n",
       "  z: -0.07289092242717743\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4721885025501251\n",
       "  y: 0.391743928194046\n",
       "  z: -0.030816124752163887\n",
       "}\n",
       "landmark {\n",
       "  x: 0.45111340284347534\n",
       "  y: 0.398140013217926\n",
       "  z: -0.02140994369983673\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41812664270401\n",
       "  y: 0.3383544385433197\n",
       "  z: 0.025417380034923553\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5361232161521912\n",
       "  y: 0.4120149314403534\n",
       "  z: -0.03653460741043091\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5106158256530762\n",
       "  y: 0.4414401054382324\n",
       "  z: -0.011890597641468048\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47759711742401123\n",
       "  y: 0.6605438590049744\n",
       "  z: 0.007772973272949457\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4035353660583496\n",
       "  y: 0.6499947309494019\n",
       "  z: 0.12356153130531311\n",
       "}\n",
       "landmark {\n",
       "  x: 0.526093065738678\n",
       "  y: 0.5899274349212646\n",
       "  z: -0.03565995395183563\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5385839939117432\n",
       "  y: 0.5977404117584229\n",
       "  z: -0.03436252102255821\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49235421419143677\n",
       "  y: 0.6596753001213074\n",
       "  z: 0.007942087016999722\n",
       "}\n",
       "landmark {\n",
       "  x: 0.498282790184021\n",
       "  y: 0.6593090295791626\n",
       "  z: 0.004857952706515789\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4419347643852234\n",
       "  y: 0.382050096988678\n",
       "  z: -0.016674287617206573\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5147088766098022\n",
       "  y: 0.5852357149124146\n",
       "  z: -0.034145109355449677\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5001249313354492\n",
       "  y: 0.39452439546585083\n",
       "  z: -0.03613460808992386\n",
       "}\n",
       "landmark {\n",
       "  x: 0.497989296913147\n",
       "  y: 0.37581998109817505\n",
       "  z: -0.040690548717975616\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4834122657775879\n",
       "  y: 0.29355114698410034\n",
       "  z: -0.02593979425728321\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4302390515804291\n",
       "  y: 0.3593946397304535\n",
       "  z: 0.0011134197702631354\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4925159215927124\n",
       "  y: 0.33351683616638184\n",
       "  z: -0.033787958323955536\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4253685772418976\n",
       "  y: 0.4007503390312195\n",
       "  z: 0.0007398506859317422\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4132908582687378\n",
       "  y: 0.3884066939353943\n",
       "  z: 0.02577178180217743\n",
       "}\n",
       "landmark {\n",
       "  x: 0.542090892791748\n",
       "  y: 0.6601888537406921\n",
       "  z: -0.03036459907889366\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5253758430480957\n",
       "  y: 0.6602001190185547\n",
       "  z: -0.02335810288786888\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5122500658035278\n",
       "  y: 0.6598601341247559\n",
       "  z: -0.014192847535014153\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5295864343643188\n",
       "  y: 0.5934630036354065\n",
       "  z: -0.03166790306568146\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4955233335494995\n",
       "  y: 0.6595594882965088\n",
       "  z: 0.006481670308858156\n",
       "}\n",
       "landmark {\n",
       "  x: 0.503230631351471\n",
       "  y: 0.6640662550926208\n",
       "  z: -0.001509196008555591\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49943289160728455\n",
       "  y: 0.6590069532394409\n",
       "  z: 0.0046163881197571754\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5359483361244202\n",
       "  y: 0.5864444375038147\n",
       "  z: -0.055338259786367416\n",
       "}\n",
       "landmark {\n",
       "  x: 0.517609715461731\n",
       "  y: 0.6617239713668823\n",
       "  z: -0.008028794080018997\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5297137498855591\n",
       "  y: 0.6647716164588928\n",
       "  z: -0.013735179789364338\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5434795618057251\n",
       "  y: 0.66798996925354\n",
       "  z: -0.01803985796868801\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5370582938194275\n",
       "  y: 0.7163671255111694\n",
       "  z: -0.008655698038637638\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5406175255775452\n",
       "  y: 0.694899320602417\n",
       "  z: -0.02163323014974594\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5419209003448486\n",
       "  y: 0.68355393409729\n",
       "  z: -0.02326815389096737\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5428435802459717\n",
       "  y: 0.6743480563163757\n",
       "  z: -0.020235681906342506\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5438441634178162\n",
       "  y: 0.6682550311088562\n",
       "  z: -0.01818024553358555\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5167147517204285\n",
       "  y: 0.6631467342376709\n",
       "  z: -0.007935346104204655\n",
       "}\n",
       "landmark {\n",
       "  x: 0.51508629322052\n",
       "  y: 0.6649717092514038\n",
       "  z: -0.010278508067131042\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5125659704208374\n",
       "  y: 0.6697496175765991\n",
       "  z: -0.01218847930431366\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5101287961006165\n",
       "  y: 0.6763843894004822\n",
       "  z: -0.009630493819713593\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49654465913772583\n",
       "  y: 0.6328473687171936\n",
       "  z: -0.013485121540725231\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3893963098526001\n",
       "  y: 0.5511819124221802\n",
       "  z: 0.13418559730052948\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5637006759643555\n",
       "  y: 0.6050231456756592\n",
       "  z: -0.046838343143463135\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5085082054138184\n",
       "  y: 0.6617729067802429\n",
       "  z: -0.0005039297975599766\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5063210129737854\n",
       "  y: 0.6619530916213989\n",
       "  z: -0.0018930670339614153\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5434929728507996\n",
       "  y: 0.6075160503387451\n",
       "  z: -0.034454915672540665\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5188246965408325\n",
       "  y: 0.5969101190567017\n",
       "  z: -0.022154182195663452\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5411581993103027\n",
       "  y: 0.6029348969459534\n",
       "  z: -0.03462221473455429\n",
       "}\n",
       "landmark {\n",
       "  x: 0.50275057554245\n",
       "  y: 0.5244846343994141\n",
       "  z: -0.01382371038198471\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4785485863685608\n",
       "  y: 0.5356225967407227\n",
       "  z: -0.010438447818160057\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5121613144874573\n",
       "  y: 0.5739749670028687\n",
       "  z: -0.03067515417933464\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4444431960582733\n",
       "  y: 0.3104574680328369\n",
       "  z: -0.0027445186860859394\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4555782079696655\n",
       "  y: 0.3398096561431885\n",
       "  z: -0.018258480355143547\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46676889061927795\n",
       "  y: 0.37303048372268677\n",
       "  z: -0.030371403321623802\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5019480586051941\n",
       "  y: 0.6938430666923523\n",
       "  z: 0.0004550619632937014\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5330036282539368\n",
       "  y: 0.3827473819255829\n",
       "  z: -0.04434482380747795\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5291785001754761\n",
       "  y: 0.3356086015701294\n",
       "  z: -0.040930163115262985\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5239855051040649\n",
       "  y: 0.28778138756752014\n",
       "  z: -0.03675893694162369\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46071451902389526\n",
       "  y: 0.4750838279724121\n",
       "  z: -0.001281876116991043\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4245389401912689\n",
       "  y: 0.49061769247055054\n",
       "  z: 0.018134893849492073\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5206112861633301\n",
       "  y: 0.4710468351840973\n",
       "  z: -0.004029407631605864\n",
       "}\n",
       "landmark {\n",
       "  x: 0.44200190901756287\n",
       "  y: 0.44170042872428894\n",
       "  z: 0.0009538815938867629\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5299409627914429\n",
       "  y: 0.5020793080329895\n",
       "  z: -0.023598797619342804\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5270994901657104\n",
       "  y: 0.5727225542068481\n",
       "  z: -0.05621286854147911\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40808457136154175\n",
       "  y: 0.5028197765350342\n",
       "  z: 0.033561792224645615\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4349793493747711\n",
       "  y: 0.5055171251296997\n",
       "  z: 0.007646191865205765\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4540201425552368\n",
       "  y: 0.5145211815834045\n",
       "  z: -0.0029752247501164675\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48176711797714233\n",
       "  y: 0.5141706466674805\n",
       "  z: -0.006841971538960934\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5024421215057373\n",
       "  y: 0.5077396631240845\n",
       "  z: -0.008965125307440758\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5180953145027161\n",
       "  y: 0.4992764890193939\n",
       "  z: -0.011753973551094532\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5519047379493713\n",
       "  y: 0.47642332315444946\n",
       "  z: -0.03886215761303902\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40902847051620483\n",
       "  y: 0.544879674911499\n",
       "  z: 0.03347880020737648\n",
       "}\n",
       "landmark {\n",
       "  x: 0.42872634530067444\n",
       "  y: 0.4354648292064667\n",
       "  z: 0.006082227919250727\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5576143264770508\n",
       "  y: 0.6003860831260681\n",
       "  z: -0.0657777190208435\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5198286175727844\n",
       "  y: 0.5345805287361145\n",
       "  z: -0.022897791117429733\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3870992064476013\n",
       "  y: 0.4596533179283142\n",
       "  z: 0.11385060846805573\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5299254655838013\n",
       "  y: 0.48895639181137085\n",
       "  z: -0.01395741943269968\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5097979307174683\n",
       "  y: 0.5740863680839539\n",
       "  z: -0.016418714076280594\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4497373700141907\n",
       "  y: 0.45724835991859436\n",
       "  z: 0.006779571063816547\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5263145565986633\n",
       "  y: 0.558498203754425\n",
       "  z: -0.05176218971610069\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3940885066986084\n",
       "  y: 0.5999355316162109\n",
       "  z: 0.13252635300159454\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5200942754745483\n",
       "  y: 0.46388939023017883\n",
       "  z: -0.0018414907390251756\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5402869582176208\n",
       "  y: 0.5485928654670715\n",
       "  z: -0.06519824266433716\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4371989071369171\n",
       "  y: 0.6995943188667297\n",
       "  z: 0.05431699380278587\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4371643662452698\n",
       "  y: 0.7211009860038757\n",
       "  z: 0.08164302259683609\n",
       "}\n",
       "landmark {\n",
       "  x: 0.39345115423202515\n",
       "  y: 0.54918372631073\n",
       "  z: 0.08301443606615067\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41805464029312134\n",
       "  y: 0.671798825263977\n",
       "  z: 0.06878992170095444\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40323692560195923\n",
       "  y: 0.4227111339569092\n",
       "  z: 0.050164688378572464\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4974830150604248\n",
       "  y: 0.7695936560630798\n",
       "  z: 0.017432251945137978\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5579516887664795\n",
       "  y: 0.6037619113922119\n",
       "  z: -0.04640193283557892\n",
       "}\n",
       "landmark {\n",
       "  x: 0.505794107913971\n",
       "  y: 0.5478297472000122\n",
       "  z: -0.017582982778549194\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41032856702804565\n",
       "  y: 0.46488380432128906\n",
       "  z: 0.034887030720710754\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4748610854148865\n",
       "  y: 0.4678306579589844\n",
       "  z: -0.006212552078068256\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4872964918613434\n",
       "  y: 0.4702393710613251\n",
       "  z: -0.008538824506103992\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4998435378074646\n",
       "  y: 0.6679104566574097\n",
       "  z: 0.0009792823111638427\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40976911783218384\n",
       "  y: 0.5856503844261169\n",
       "  z: 0.042265210300683975\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5223226547241211\n",
       "  y: 0.7955501079559326\n",
       "  z: 0.02542964369058609\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47973158955574036\n",
       "  y: 0.7680007219314575\n",
       "  z: 0.048591192811727524\n",
       "}\n",
       "landmark {\n",
       "  x: 0.460330069065094\n",
       "  y: 0.7488943934440613\n",
       "  z: 0.06302400678396225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5695129632949829\n",
       "  y: 0.34022432565689087\n",
       "  z: -0.040185555815696716\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5501523017883301\n",
       "  y: 0.7993963956832886\n",
       "  z: 0.024462761357426643\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4990178942680359\n",
       "  y: 0.46967002749443054\n",
       "  z: -0.007992714643478394\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5099785327911377\n",
       "  y: 0.46691352128982544\n",
       "  z: -0.005389996338635683\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5167174339294434\n",
       "  y: 0.4652462303638458\n",
       "  z: -0.0021174419671297073\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41696685552597046\n",
       "  y: 0.429181843996048\n",
       "  z: 0.018741734325885773\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5083186030387878\n",
       "  y: 0.45459482073783875\n",
       "  z: -0.009383701719343662\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49610358476638794\n",
       "  y: 0.4517362713813782\n",
       "  z: -0.013356154784560204\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4846906065940857\n",
       "  y: 0.45092496275901794\n",
       "  z: -0.013880027458071709\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47268420457839966\n",
       "  y: 0.4522702693939209\n",
       "  z: -0.011060100980103016\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4644223749637604\n",
       "  y: 0.4548684358596802\n",
       "  z: -0.006881546229124069\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3917457163333893\n",
       "  y: 0.4120867848396301\n",
       "  z: 0.08671876788139343\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4663156270980835\n",
       "  y: 0.464622437953949\n",
       "  z: -0.0026871112640947104\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5615519285202026\n",
       "  y: 0.6238124370574951\n",
       "  z: -0.03227417543530464\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5112894177436829\n",
       "  y: 0.6240540742874146\n",
       "  z: -0.021278079599142075\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5263773202896118\n",
       "  y: 0.5875112414360046\n",
       "  z: -0.041131701320409775\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5411792397499084\n",
       "  y: 0.6230437159538269\n",
       "  z: -0.03286740928888321\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5659016966819763\n",
       "  y: 0.4452763497829437\n",
       "  z: -0.03508855402469635\n",
       "}\n",
       "landmark {\n",
       "  x: 0.45776069164276123\n",
       "  y: 0.7272451519966125\n",
       "  z: 0.043628714978694916\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47700196504592896\n",
       "  y: 0.7488013505935669\n",
       "  z: 0.03145822882652283\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5224996209144592\n",
       "  y: 0.7841222286224365\n",
       "  z: 0.006181269884109497\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4185143709182739\n",
       "  y: 0.6905184388160706\n",
       "  z: 0.10453860461711884\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5166275501251221\n",
       "  y: 0.459827721118927\n",
       "  z: -0.00497309397906065\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5414918065071106\n",
       "  y: 0.5092448592185974\n",
       "  z: -0.04169674962759018\n",
       "}\n",
       "landmark {\n",
       "  x: 0.552142858505249\n",
       "  y: 0.7876219153404236\n",
       "  z: 0.005739530548453331\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49987757205963135\n",
       "  y: 0.7842663526535034\n",
       "  z: 0.03376861289143562\n",
       "}\n",
       "landmark {\n",
       "  x: 0.39701637625694275\n",
       "  y: 0.5937459468841553\n",
       "  z: 0.08540800213813782\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5292631983757019\n",
       "  y: 0.6655085682868958\n",
       "  z: -0.013849509879946709\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5274563431739807\n",
       "  y: 0.6696949601173401\n",
       "  z: -0.01644124835729599\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5257969498634338\n",
       "  y: 0.6769515872001648\n",
       "  z: -0.018988560885190964\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5241155624389648\n",
       "  y: 0.6872332096099854\n",
       "  z: -0.0168809425085783\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5177127122879028\n",
       "  y: 0.7066090106964111\n",
       "  z: -0.0059674945659935474\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5048183798789978\n",
       "  y: 0.6612937450408936\n",
       "  z: -0.0022634968627244234\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5012533068656921\n",
       "  y: 0.6596871614456177\n",
       "  z: -0.002784251468256116\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49743297696113586\n",
       "  y: 0.6567737460136414\n",
       "  z: -0.0037107267417013645\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4838106036186218\n",
       "  y: 0.6449294686317444\n",
       "  z: -0.003446538234129548\n",
       "}\n",
       "landmark {\n",
       "  x: 0.428785502910614\n",
       "  y: 0.5974475741386414\n",
       "  z: 0.016546126455068588\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5411766171455383\n",
       "  y: 0.48803696036338806\n",
       "  z: -0.030277660116553307\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5326139330863953\n",
       "  y: 0.4488500654697418\n",
       "  z: -0.01075214147567749\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5231509208679199\n",
       "  y: 0.4535961151123047\n",
       "  z: -0.007004957180470228\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5074053406715393\n",
       "  y: 0.6590255498886108\n",
       "  z: -0.0007390629034489393\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4252074956893921\n",
       "  y: 0.644523024559021\n",
       "  z: 0.04082956910133362\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5465689897537231\n",
       "  y: 0.44755253195762634\n",
       "  z: -0.02764202281832695\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5084198117256165\n",
       "  y: 0.7287415862083435\n",
       "  z: 0.001449663657695055\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5671145915985107\n",
       "  y: 0.5177446007728577\n",
       "  z: -0.06446689367294312\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5529282093048096\n",
       "  y: 0.4994427561759949\n",
       "  z: -0.05129912868142128\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5666766166687012\n",
       "  y: 0.49590086936950684\n",
       "  z: -0.0534198172390461\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5300586819648743\n",
       "  y: 0.5406211018562317\n",
       "  z: -0.0402037538588047\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5537114143371582\n",
       "  y: 0.7682908773422241\n",
       "  z: -0.004090125672519207\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5549527406692505\n",
       "  y: 0.7420862913131714\n",
       "  z: -0.006435346323996782\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5310974717140198\n",
       "  y: 0.7404388189315796\n",
       "  z: -0.005397108383476734\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4757339060306549\n",
       "  y: 0.6896182894706726\n",
       "  z: 0.013779869303107262\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49721866846084595\n",
       "  y: 0.5887948870658875\n",
       "  z: -0.012562914751470089\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49086031317710876\n",
       "  y: 0.7119529247283936\n",
       "  z: 0.008586977608501911\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46277564764022827\n",
       "  y: 0.5830336213111877\n",
       "  z: -0.009406177327036858\n",
       "}\n",
       "landmark {\n",
       "  x: 0.48220425844192505\n",
       "  y: 0.6069447994232178\n",
       "  z: -0.009150341153144836\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4481115937232971\n",
       "  y: 0.6134777665138245\n",
       "  z: 0.002963524078950286\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5253166556358337\n",
       "  y: 0.7655734419822693\n",
       "  z: -0.003004259429872036\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5198787450790405\n",
       "  y: 0.5504860877990723\n",
       "  z: -0.030070561915636063\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46313560009002686\n",
       "  y: 0.7051988244056702\n",
       "  z: 0.026845591142773628\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4820384681224823\n",
       "  y: 0.7290677428245544\n",
       "  z: 0.019510924816131592\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46365994215011597\n",
       "  y: 0.6642888784408569\n",
       "  z: 0.01266307383775711\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41204720735549927\n",
       "  y: 0.6198068857192993\n",
       "  z: 0.05051353946328163\n",
       "}\n",
       "landmark {\n",
       "  x: 0.44486746191978455\n",
       "  y: 0.6668654680252075\n",
       "  z: 0.02533852495253086\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4034789800643921\n",
       "  y: 0.6344766616821289\n",
       "  z: 0.08347069472074509\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46852341294288635\n",
       "  y: 0.6301552653312683\n",
       "  z: -0.001609396655112505\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5308426022529602\n",
       "  y: 0.5217477083206177\n",
       "  z: -0.03159766644239426\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5315727591514587\n",
       "  y: 0.5827627778053284\n",
       "  z: -0.058622095733881\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5205541849136353\n",
       "  y: 0.5851976871490479\n",
       "  z: -0.043315887451171875\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5397776365280151\n",
       "  y: 0.5703680515289307\n",
       "  z: -0.06810992956161499\n",
       "}\n",
       "landmark {\n",
       "  x: 0.521752119064331\n",
       "  y: 0.4317142069339752\n",
       "  z: -0.017554394900798798\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4993756413459778\n",
       "  y: 0.4208834767341614\n",
       "  z: -0.022501375526189804\n",
       "}\n",
       "landmark {\n",
       "  x: 0.47987791895866394\n",
       "  y: 0.41805756092071533\n",
       "  z: -0.02346690557897091\n",
       "}\n",
       "landmark {\n",
       "  x: 0.46280795335769653\n",
       "  y: 0.4199369549751282\n",
       "  z: -0.01880975067615509\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4498136043548584\n",
       "  y: 0.4272858202457428\n",
       "  z: -0.010558896698057652\n",
       "}\n",
       "landmark {\n",
       "  x: 0.43840888142585754\n",
       "  y: 0.4596605896949768\n",
       "  z: 0.012267941609025002\n",
       "}\n",
       "landmark {\n",
       "  x: 0.39180105924606323\n",
       "  y: 0.5057798027992249\n",
       "  z: 0.07581013441085815\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4493664503097534\n",
       "  y: 0.4878775179386139\n",
       "  z: 0.004609411116689444\n",
       "}\n",
       "landmark {\n",
       "  x: 0.464398592710495\n",
       "  y: 0.49461981654167175\n",
       "  z: -0.0017758278409019113\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4836979806423187\n",
       "  y: 0.4964679777622223\n",
       "  z: -0.0056196581572294235\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5019764304161072\n",
       "  y: 0.4931826591491699\n",
       "  z: -0.007354678586125374\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5162962079048157\n",
       "  y: 0.4871281087398529\n",
       "  z: -0.006470981054008007\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5260936617851257\n",
       "  y: 0.4806525707244873\n",
       "  z: -0.007380414288491011\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3878113031387329\n",
       "  y: 0.5050774812698364\n",
       "  z: 0.1283656358718872\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5201742053031921\n",
       "  y: 0.5893748998641968\n",
       "  z: -0.03591766580939293\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5419909358024597\n",
       "  y: 0.5284222364425659\n",
       "  z: -0.051474008709192276\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5431222915649414\n",
       "  y: 0.5859175324440002\n",
       "  z: -0.06800699979066849\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5500196218490601\n",
       "  y: 0.595791757106781\n",
       "  z: -0.06070886179804802\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5421998500823975\n",
       "  y: 0.5886105298995972\n",
       "  z: -0.061096467077732086\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5237369537353516\n",
       "  y: 0.5952004194259644\n",
       "  z: -0.03000873513519764\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5529462099075317\n",
       "  y: 0.5983679890632629\n",
       "  z: -0.06414540112018585\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5532392859458923\n",
       "  y: 0.6017192006111145\n",
       "  z: -0.04710717126727104\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5254664421081543\n",
       "  y: 0.4650709629058838\n",
       "  z: -0.0028078474570065737\n",
       "}\n",
       "landmark {\n",
       "  x: 0.534076452255249\n",
       "  y: 0.46971309185028076\n",
       "  z: -0.009624967351555824\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5391921997070312\n",
       "  y: 0.47339585423469543\n",
       "  z: -0.01815629191696644\n",
       "}\n",
       "landmark {\n",
       "  x: 0.45913583040237427\n",
       "  y: 0.45645326375961304\n",
       "  z: -0.002094714203849435\n",
       "}\n",
       "landmark {\n",
       "  x: 0.45157498121261597\n",
       "  y: 0.4464888870716095\n",
       "  z: -0.0019425359787419438\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5785282850265503\n",
       "  y: 0.5216383337974548\n",
       "  z: -0.05794941261410713\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6588695049285889\n",
       "  y: 0.47542938590049744\n",
       "  z: 0.022719645872712135\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5764408111572266\n",
       "  y: 0.5996464490890503\n",
       "  z: -0.04539216309785843\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7056013345718384\n",
       "  y: 0.3959643244743347\n",
       "  z: 0.08840437233448029\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6189530491828918\n",
       "  y: 0.4892745018005371\n",
       "  z: 0.005316348280757666\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6326648592948914\n",
       "  y: 0.49174952507019043\n",
       "  z: 0.008195345290005207\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6456596851348877\n",
       "  y: 0.4911421835422516\n",
       "  z: 0.013546206057071686\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6630433201789856\n",
       "  y: 0.48207470774650574\n",
       "  z: 0.026498928666114807\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6078014373779297\n",
       "  y: 0.48299795389175415\n",
       "  z: 0.0052191149443387985\n",
       "}\n",
       "landmark {\n",
       "  x: 0.639495313167572\n",
       "  y: 0.44548654556274414\n",
       "  z: -0.0020088572055101395\n",
       "}\n",
       "landmark {\n",
       "  x: 0.625726044178009\n",
       "  y: 0.4452497363090515\n",
       "  z: -0.0036411043256521225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6522046327590942\n",
       "  y: 0.4487597644329071\n",
       "  z: 0.004850402940064669\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6603572964668274\n",
       "  y: 0.4552159905433655\n",
       "  z: 0.012136781588196754\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6727895736694336\n",
       "  y: 0.4932643175125122\n",
       "  z: 0.03563347086310387\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6024027466773987\n",
       "  y: 0.7536580562591553\n",
       "  z: 0.017995281144976616\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6632847189903259\n",
       "  y: 0.47193238139152527\n",
       "  z: 0.02757519856095314\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7054145932197571\n",
       "  y: 0.48306435346603394\n",
       "  z: 0.1022832840681076\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6871585845947266\n",
       "  y: 0.47956860065460205\n",
       "  z: 0.050409089773893356\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6296486258506775\n",
       "  y: 0.5705260634422302\n",
       "  z: -0.0008459174423478544\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5785712003707886\n",
       "  y: 0.6511898040771484\n",
       "  z: -0.02937227301299572\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5752492547035217\n",
       "  y: 0.6687517166137695\n",
       "  z: -0.020908905193209648\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5960960984230042\n",
       "  y: 0.6551768779754639\n",
       "  z: -0.018194876611232758\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6068844795227051\n",
       "  y: 0.6603049039840698\n",
       "  z: -0.005159022286534309\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5882235169410706\n",
       "  y: 0.6684905886650085\n",
       "  z: -0.013181176036596298\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5981532335281372\n",
       "  y: 0.6684212684631348\n",
       "  z: -0.0017488528974354267\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6188094019889832\n",
       "  y: 0.6862189173698425\n",
       "  z: 0.020000431686639786\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5778798460960388\n",
       "  y: 0.5915349721908569\n",
       "  z: -0.07139408588409424\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5805217623710632\n",
       "  y: 0.570936918258667\n",
       "  z: -0.07678399235010147\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6853268146514893\n",
       "  y: 0.4285944700241089\n",
       "  z: 0.017322923988103867\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6032040119171143\n",
       "  y: 0.5198140144348145\n",
       "  z: -0.00894963089376688\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6072242259979248\n",
       "  y: 0.5834707617759705\n",
       "  z: -0.033692386001348495\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6077300906181335\n",
       "  y: 0.5718020796775818\n",
       "  z: -0.029927976429462433\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6686056852340698\n",
       "  y: 0.568183422088623\n",
       "  z: 0.022675471380352974\n",
       "}\n",
       "landmark {\n",
       "  x: 0.57989501953125\n",
       "  y: 0.5442107915878296\n",
       "  z: -0.07000764459371567\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6573443412780762\n",
       "  y: 0.40517061948776245\n",
       "  z: -0.012269874103367329\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6744274497032166\n",
       "  y: 0.41348737478256226\n",
       "  z: 0.0016722604632377625\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6978675127029419\n",
       "  y: 0.3591703772544861\n",
       "  z: 0.05584437772631645\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5969459414482117\n",
       "  y: 0.4165716767311096\n",
       "  z: -0.03035866841673851\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6130215525627136\n",
       "  y: 0.4492724537849426\n",
       "  z: -0.00046875193947926164\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6309720277786255\n",
       "  y: 0.6685632467269897\n",
       "  z: 0.02384357340633869\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6742590665817261\n",
       "  y: 0.6625540256500244\n",
       "  z: 0.1552211046218872\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5966936945915222\n",
       "  y: 0.5944876670837402\n",
       "  z: -0.02928764931857586\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5848938822746277\n",
       "  y: 0.6007360219955444\n",
       "  z: -0.031146416440606117\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6182188987731934\n",
       "  y: 0.6669655442237854\n",
       "  z: 0.022002311423420906\n",
       "}\n",
       "landmark {\n",
       "  x: 0.612289309501648\n",
       "  y: 0.6660574078559875\n",
       "  z: 0.017113039270043373\n",
       "}\n",
       "landmark {\n",
       "  x: 0.683069109916687\n",
       "  y: 0.39873582124710083\n",
       "  z: 0.007948148064315319\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6067410111427307\n",
       "  y: 0.5908854007720947\n",
       "  z: -0.02538110688328743\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6323742866516113\n",
       "  y: 0.40430694818496704\n",
       "  z: -0.02353445626795292\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6363219022750854\n",
       "  y: 0.3860655426979065\n",
       "  z: -0.02761700376868248\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6500265598297119\n",
       "  y: 0.30673283338546753\n",
       "  z: -0.008519281633198261\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6909261345863342\n",
       "  y: 0.37811410427093506\n",
       "  z: 0.028331544250249863\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6423740983009338\n",
       "  y: 0.34501686692237854\n",
       "  z: -0.018717210739850998\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6933632493019104\n",
       "  y: 0.4186735153198242\n",
       "  z: 0.029178636148571968\n",
       "}\n",
       "landmark {\n",
       "  x: 0.700027585029602\n",
       "  y: 0.4083685874938965\n",
       "  z: 0.05669810250401497\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5772833228111267\n",
       "  y: 0.6621822714805603\n",
       "  z: -0.026567630469799042\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5917488932609558\n",
       "  y: 0.6638122797012329\n",
       "  z: -0.016183195635676384\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6025052666664124\n",
       "  y: 0.6649157404899597\n",
       "  z: -0.004546548705548048\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5929277539253235\n",
       "  y: 0.5975856184959412\n",
       "  z: -0.0262665543705225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6152205467224121\n",
       "  y: 0.6664934158325195\n",
       "  z: 0.01927119307219982\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6089156866073608\n",
       "  y: 0.6701775789260864\n",
       "  z: 0.009379224851727486\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6105522513389587\n",
       "  y: 0.6655819416046143\n",
       "  z: 0.016507258638739586\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5907332301139832\n",
       "  y: 0.5898719429969788\n",
       "  z: -0.04928597807884216\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5952021479606628\n",
       "  y: 0.6662712097167969\n",
       "  z: 0.0004962275852449238\n",
       "}\n",
       "landmark {\n",
       "  x: 0.584912121295929\n",
       "  y: 0.6680944561958313\n",
       "  z: -0.0076348138973116875\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5728012323379517\n",
       "  y: 0.6697721481323242\n",
       "  z: -0.014575955457985401\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5740765333175659\n",
       "  y: 0.7180237770080566\n",
       "  z: -0.005287169478833675\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5752920508384705\n",
       "  y: 0.6965925693511963\n",
       "  z: -0.01811111904680729\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5755575299263\n",
       "  y: 0.6851645708084106\n",
       "  z: -0.019672060385346413\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5750489830970764\n",
       "  y: 0.6760945320129395\n",
       "  z: -0.01653561368584633\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5740312933921814\n",
       "  y: 0.6699258685112\n",
       "  z: -0.014600689522922039\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5971511602401733\n",
       "  y: 0.6678041815757751\n",
       "  z: 0.0003688416909426451\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5989142656326294\n",
       "  y: 0.6696732640266418\n",
       "  z: -0.00190642848610878\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6011472940444946\n",
       "  y: 0.6746355891227722\n",
       "  z: -0.0035719028674066067\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6028622388839722\n",
       "  y: 0.6813968420028687\n",
       "  z: -0.00022549593995790929\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6185097694396973\n",
       "  y: 0.6395864486694336\n",
       "  z: -0.0014492120826616883\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6929223537445068\n",
       "  y: 0.5685340166091919\n",
       "  z: 0.16924187541007996\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6033219695091248\n",
       "  y: 0.6673420667648315\n",
       "  z: 0.009844617918133736\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6060069799423218\n",
       "  y: 0.667858362197876\n",
       "  z: 0.008576026186347008\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5798728466033936\n",
       "  y: 0.6097392439842224\n",
       "  z: -0.03119889460504055\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6011130213737488\n",
       "  y: 0.6020265221595764\n",
       "  z: -0.015233676880598068\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5822636485099792\n",
       "  y: 0.6054966449737549\n",
       "  z: -0.031560566276311874\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6170055270195007\n",
       "  y: 0.531817615032196\n",
       "  z: -0.00132173509337008\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6388397216796875\n",
       "  y: 0.5454719662666321\n",
       "  z: 0.00636491971090436\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6090685725212097\n",
       "  y: 0.5798870325088501\n",
       "  z: -0.02117055281996727\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6806395053863525\n",
       "  y: 0.32868343591690063\n",
       "  z: 0.021805766969919205\n",
       "}\n",
       "landmark {\n",
       "  x: 0.672931432723999\n",
       "  y: 0.3560013771057129\n",
       "  z: 0.003641661023721099\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6635937094688416\n",
       "  y: 0.3871806263923645\n",
       "  z: -0.010851099155843258\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6068069934844971\n",
       "  y: 0.6988049745559692\n",
       "  z: 0.011244765482842922\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6032966375350952\n",
       "  y: 0.3881467282772064\n",
       "  z: -0.03770419955253601\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6087865829467773\n",
       "  y: 0.341869056224823\n",
       "  z: -0.03312527760863304\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6142168045043945\n",
       "  y: 0.2949202060699463\n",
       "  z: -0.02807466685771942\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6567813158035278\n",
       "  y: 0.4882495701313019\n",
       "  z: 0.020680956542491913\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6856184005737305\n",
       "  y: 0.5068051218986511\n",
       "  z: 0.04603695869445801\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6011501550674438\n",
       "  y: 0.47709065675735474\n",
       "  z: 0.0058264653198421\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6755964159965515\n",
       "  y: 0.45738470554351807\n",
       "  z: 0.026608232408761978\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5945607423782349\n",
       "  y: 0.5063700675964355\n",
       "  z: -0.01608158089220524\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6000203490257263\n",
       "  y: 0.5774354338645935\n",
       "  z: -0.049024924635887146\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6966537237167358\n",
       "  y: 0.5203132033348083\n",
       "  z: 0.06516062468290329\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6772083044052124\n",
       "  y: 0.5204225778579712\n",
       "  z: 0.03382159397006035\n",
       "}\n",
       "landmark {\n",
       "  x: 0.66111159324646\n",
       "  y: 0.5272020101547241\n",
       "  z: 0.01929229311645031\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6360732316970825\n",
       "  y: 0.5239739418029785\n",
       "  z: 0.010193143039941788\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6171277761459351\n",
       "  y: 0.515178382396698\n",
       "  z: 0.004110187757760286\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6032440066337585\n",
       "  y: 0.5050035715103149\n",
       "  z: -0.0019802330061793327\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5789397358894348\n",
       "  y: 0.47826316952705383\n",
       "  z: -0.03574259206652641\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6935153007507324\n",
       "  y: 0.56117844581604\n",
       "  z: 0.06490177661180496\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6869459748268127\n",
       "  y: 0.4525235891342163\n",
       "  z: 0.03419231250882149\n",
       "}\n",
       "landmark {\n",
       "  x: 0.571871280670166\n",
       "  y: 0.6012559533119202\n",
       "  z: -0.06420423835515976\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6024228930473328\n",
       "  y: 0.5398944616317749\n",
       "  z: -0.013723471201956272\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7041307687759399\n",
       "  y: 0.4805258810520172\n",
       "  z: 0.1502646654844284\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5934885740280151\n",
       "  y: 0.49340832233428955\n",
       "  z: -0.006284606643021107\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6091266870498657\n",
       "  y: 0.5800704956054688\n",
       "  z: -0.006746835075318813\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6671428680419922\n",
       "  y: 0.4721260368824005\n",
       "  z: 0.031090084463357925\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6002978086471558\n",
       "  y: 0.5631557106971741\n",
       "  z: -0.04445667937397957\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6852114200592041\n",
       "  y: 0.6149562001228333\n",
       "  z: 0.1662759631872177\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6015353202819824\n",
       "  y: 0.4700983166694641\n",
       "  z: 0.00851505622267723\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5906012058258057\n",
       "  y: 0.551639199256897\n",
       "  z: -0.059905268251895905\n",
       "}\n",
       "landmark {\n",
       "  x: 0.654043972492218\n",
       "  y: 0.7082507014274597\n",
       "  z: 0.07751923054456711\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6468997597694397\n",
       "  y: 0.7285116314888\n",
       "  z: 0.10552646964788437\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6988212466239929\n",
       "  y: 0.5661715865135193\n",
       "  z: 0.1173894926905632\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6700619459152222\n",
       "  y: 0.6831300258636475\n",
       "  z: 0.09631188213825226\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7029876708984375\n",
       "  y: 0.4428701400756836\n",
       "  z: 0.0832875519990921\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6024916172027588\n",
       "  y: 0.772515594959259\n",
       "  z: 0.028658783063292503\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5692941546440125\n",
       "  y: 0.6044465899467468\n",
       "  z: -0.04545144736766815\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6136380434036255\n",
       "  y: 0.5544629693031311\n",
       "  z: -0.006408297456800938\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6967185139656067\n",
       "  y: 0.48312628269195557\n",
       "  z: 0.06619679182767868\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6455045938491821\n",
       "  y: 0.47981661558151245\n",
       "  z: 0.01317405141890049\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6333754658699036\n",
       "  y: 0.4808330535888672\n",
       "  z: 0.008582770824432373\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6115293502807617\n",
       "  y: 0.6740792393684387\n",
       "  z: 0.012437904253602028\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6887950897216797\n",
       "  y: 0.6004934310913086\n",
       "  z: 0.07240128517150879\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5767170190811157\n",
       "  y: 0.7966068983078003\n",
       "  z: 0.03168965131044388\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6126894950866699\n",
       "  y: 0.7712750434875488\n",
       "  z: 0.06404510885477066\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6281360983848572\n",
       "  y: 0.7536602020263672\n",
       "  z: 0.08252831548452377\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6217703819274902\n",
       "  y: 0.47883304953575134\n",
       "  z: 0.0065095145255327225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6111698150634766\n",
       "  y: 0.47448766231536865\n",
       "  z: 0.0070813242346048355\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6047274470329285\n",
       "  y: 0.4719637632369995\n",
       "  z: 0.009042899124324322\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6955739259719849\n",
       "  y: 0.4475337564945221\n",
       "  z: 0.04896966740489006\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6132535934448242\n",
       "  y: 0.46238601207733154\n",
       "  z: 0.00313969305716455\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6249765157699585\n",
       "  y: 0.46113321185112\n",
       "  z: 0.0013553907629102468\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6364565491676331\n",
       "  y: 0.4616742730140686\n",
       "  z: 0.0034788574557751417\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6479704976081848\n",
       "  y: 0.4646225869655609\n",
       "  z: 0.008610299788415432\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6554908752441406\n",
       "  y: 0.4681622385978699\n",
       "  z: 0.01433696411550045\n",
       "}\n",
       "landmark {\n",
       "  x: 0.70742267370224\n",
       "  y: 0.43395617604255676\n",
       "  z: 0.12229420244693756\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6534560322761536\n",
       "  y: 0.47763216495513916\n",
       "  z: 0.018383756279945374\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6066190004348755\n",
       "  y: 0.6292018294334412\n",
       "  z: -0.012053961865603924\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5974544882774353\n",
       "  y: 0.5921003222465515\n",
       "  z: -0.03481832519173622\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5808079242706299\n",
       "  y: 0.6251600384712219\n",
       "  z: -0.028956232592463493\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6360697150230408\n",
       "  y: 0.7334192395210266\n",
       "  z: 0.0625368058681488\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6194186210632324\n",
       "  y: 0.7529348134994507\n",
       "  z: 0.046527571976184845\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5803126096725464\n",
       "  y: 0.7857524156570435\n",
       "  z: 0.01231501717120409\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6612809300422668\n",
       "  y: 0.700610339641571\n",
       "  z: 0.1325962245464325\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6052187085151672\n",
       "  y: 0.4663212299346924\n",
       "  z: 0.006339251529425383\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5874743461608887\n",
       "  y: 0.5122627019882202\n",
       "  z: -0.0365712009370327\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5965433120727539\n",
       "  y: 0.7863866090774536\n",
       "  z: 0.04511599242687225\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6915217638015747\n",
       "  y: 0.6087846755981445\n",
       "  z: 0.11824199557304382\n",
       "}\n",
       "landmark {\n",
       "  x: 0.586845874786377\n",
       "  y: 0.6687407493591309\n",
       "  z: -0.007655629422515631\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5887079238891602\n",
       "  y: 0.6730652451515198\n",
       "  z: -0.009999354369938374\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5899178385734558\n",
       "  y: 0.6803638935089111\n",
       "  z: -0.012137379497289658\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5905466079711914\n",
       "  y: 0.6905490159988403\n",
       "  z: -0.009655863977968693\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5922060012817383\n",
       "  y: 0.7100737690925598\n",
       "  z: 0.0018200495978817344\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6070432662963867\n",
       "  y: 0.6674673557281494\n",
       "  z: 0.008598624728620052\n",
       "}\n",
       "landmark {\n",
       "  x: 0.611082136631012\n",
       "  y: 0.66608726978302\n",
       "  z: 0.009008420631289482\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6149240732192993\n",
       "  y: 0.6635754108428955\n",
       "  z: 0.008935065008699894\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6281986236572266\n",
       "  y: 0.6527678966522217\n",
       "  z: 0.011536900885403156\n",
       "}\n",
       "landmark {\n",
       "  x: 0.675541341304779\n",
       "  y: 0.6108207702636719\n",
       "  z: 0.041870277374982834\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5864791870117188\n",
       "  y: 0.4911193251609802\n",
       "  z: -0.025076625868678093\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5929887890815735\n",
       "  y: 0.45339736342430115\n",
       "  z: -0.004207811783999205\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6001606583595276\n",
       "  y: 0.45941096544265747\n",
       "  z: 0.002762830350548029\n",
       "}\n",
       "landmark {\n",
       "  x: 0.603686511516571\n",
       "  y: 0.6648555994033813\n",
       "  z: 0.009651693515479565\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6712783575057983\n",
       "  y: 0.6565647125244141\n",
       "  z: 0.0664890855550766\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5828855633735657\n",
       "  y: 0.4502648711204529\n",
       "  z: -0.02359991893172264\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5974357724189758\n",
       "  y: 0.7321197390556335\n",
       "  z: 0.010269906371831894\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5790517926216125\n",
       "  y: 0.5012127757072449\n",
       "  z: -0.048601679503917694\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5958516001701355\n",
       "  y: 0.5447321534156799\n",
       "  z: -0.033524803817272186\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5772874355316162\n",
       "  y: 0.7421289682388306\n",
       "  z: -0.0012464269530028105\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6285961270332336\n",
       "  y: 0.6964722275733948\n",
       "  z: 0.02927359752357006\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6195447444915771\n",
       "  y: 0.5958673357963562\n",
       "  z: -0.0008327407413162291\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6135442852973938\n",
       "  y: 0.717044472694397\n",
       "  z: 0.020697832107543945\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6507041454315186\n",
       "  y: 0.5937256217002869\n",
       "  z: 0.008790135383605957\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6319566369056702\n",
       "  y: 0.6153952479362488\n",
       "  z: 0.005407113116234541\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6598681807518005\n",
       "  y: 0.6248791217803955\n",
       "  z: 0.023731006309390068\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5805758237838745\n",
       "  y: 0.7674301862716675\n",
       "  z: 0.0025338639970868826\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6025633811950684\n",
       "  y: 0.5556398630142212\n",
       "  z: -0.02159501053392887\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6363463401794434\n",
       "  y: 0.711950957775116\n",
       "  z: 0.04449673742055893\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6188765168190002\n",
       "  y: 0.7338395118713379\n",
       "  z: 0.03322058543562889\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6418101191520691\n",
       "  y: 0.6729598641395569\n",
       "  z: 0.031183386221528053\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6826938390731812\n",
       "  y: 0.6335778832435608\n",
       "  z: 0.07935673743486404\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6551860570907593\n",
       "  y: 0.6766151189804077\n",
       "  z: 0.04670402780175209\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6830033659934998\n",
       "  y: 0.6480540633201599\n",
       "  z: 0.1147850826382637\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6417645215988159\n",
       "  y: 0.6395465731620789\n",
       "  z: 0.015348232351243496\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5945761203765869\n",
       "  y: 0.5258291363716125\n",
       "  z: -0.02439749799668789\n",
       "}\n",
       "landmark {\n",
       "  x: 0.595435380935669\n",
       "  y: 0.586831271648407\n",
       "  z: -0.052015356719493866\n",
       "}\n",
       "landmark {\n",
       "  x: 0.603141188621521\n",
       "  y: 0.5903905630111694\n",
       "  z: -0.03568384796380997\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5912163257598877\n",
       "  y: 0.5736072063446045\n",
       "  z: -0.06321785598993301\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6054081916809082\n",
       "  y: 0.4378279447555542\n",
       "  z: -0.00835629552602768\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6279951930046082\n",
       "  y: 0.4302454888820648\n",
       "  z: -0.008929550647735596\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6464970111846924\n",
       "  y: 0.4302142858505249\n",
       "  z: -0.005684456788003445\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6616268157958984\n",
       "  y: 0.4340728521347046\n",
       "  z: 0.002699083648622036\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6715667247772217\n",
       "  y: 0.4426021873950958\n",
       "  z: 0.013580670580267906\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6760644912719727\n",
       "  y: 0.47532957792282104\n",
       "  z: 0.03815218061208725\n",
       "}\n",
       "landmark {\n",
       "  x: 0.703799307346344\n",
       "  y: 0.524653971195221\n",
       "  z: 0.11114612221717834\n",
       "}\n",
       "landmark {\n",
       "  x: 0.665608286857605\n",
       "  y: 0.5016915798187256\n",
       "  z: 0.028275778517127037\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6522108912467957\n",
       "  y: 0.5066515803337097\n",
       "  z: 0.01876259222626686\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6345593333244324\n",
       "  y: 0.5064302682876587\n",
       "  z: 0.011284506879746914\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6174914836883545\n",
       "  y: 0.501069188117981\n",
       "  z: 0.006021769717335701\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6045259833335876\n",
       "  y: 0.49329274892807007\n",
       "  z: 0.003598991548642516\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5960450172424316\n",
       "  y: 0.4857026934623718\n",
       "  z: 0.000956924632191658\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6982761025428772\n",
       "  y: 0.5242944359779358\n",
       "  z: 0.16461563110351562\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6020258069038391\n",
       "  y: 0.5945651531219482\n",
       "  z: -0.028438067063689232\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5879843235015869\n",
       "  y: 0.5312572717666626\n",
       "  z: -0.046329647302627563\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5869019031524658\n",
       "  y: 0.5886150598526001\n",
       "  z: -0.06384675949811935\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5779272317886353\n",
       "  y: 0.597436249256134\n",
       "  z: -0.05832332372665405\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5858767032623291\n",
       "  y: 0.591139018535614\n",
       "  z: -0.056856669485569\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5975630283355713\n",
       "  y: 0.599770188331604\n",
       "  z: -0.023820577189326286\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5759304165840149\n",
       "  y: 0.5997139811515808\n",
       "  z: -0.06200325861573219\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5734338164329529\n",
       "  y: 0.602863073348999\n",
       "  z: -0.04542204365134239\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5970427393913269\n",
       "  y: 0.4706280827522278\n",
       "  z: 0.005731416866183281\n",
       "}\n",
       "landmark {\n",
       "  x: 0.589739978313446\n",
       "  y: 0.47390758991241455\n",
       "  z: -0.0030349395237863064\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5865918397903442\n",
       "  y: 0.4768276810646057\n",
       "  z: -0.012699957005679607\n",
       "}\n",
       "landmark {\n",
       "  x: 0.659971296787262\n",
       "  y: 0.47037285566329956\n",
       "  z: 0.020210331305861473\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6671016216278076\n",
       "  y: 0.46133026480674744\n",
       "  z: 0.02158222161233425\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "protective-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for exported array\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "\n",
    "#Actions that we are going to detect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "\n",
    "# 30 videos worth of data\n",
    "no_sequences = 30 \n",
    "\n",
    "#30 frames of length\n",
    "sequence_length = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "perceived-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions : \n",
    "    for sequence in range(no_sequences) : \n",
    "        try : \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except : \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "framed-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic : \n",
    "    #Loop through actions \n",
    "    for action in actions :\n",
    "        #Loop through the collection of frames\n",
    "        for sequence in range(no_sequences) : \n",
    "            \n",
    "            #Loop through each frame\n",
    "            for frame_num in range(sequence_length) : \n",
    "                \n",
    "                #Reading frames\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                #Make detection \n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                draw_styled_landmarks(image, results)\n",
    "                #print(results)\n",
    "                \n",
    "                \n",
    "                #collecting images \n",
    "                \n",
    "                if frame_num == 0 : \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(image, f'Collecting frames for {action} video number {sequence}', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 4, cv2.LINE_AA)\n",
    "                    cv2.waitKey(2000)\n",
    "                else : \n",
    "                    cv2.putText(image, f'Collecting frames for {action} video number {sequence}', (15,12), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                \n",
    "                #show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                #Saving the arrays\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                #break \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q') : \n",
    "                    break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "funny-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "reported-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label : num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "selective-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'iloveyou': 2}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "mathematical-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all sequences \n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "for action in actions : \n",
    "    for sequence in range(no_sequences) : \n",
    "        window = []\n",
    "        for frame_num in range(sequence_length) : \n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), f'{str(frame_num)}.npy'))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "thermal-parks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "together-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "younger-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assumed-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "spoken-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "racial-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "smoking-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation= 'relu', input_shape = (30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(actions.shape[0], activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "economic-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'Adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hungarian-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/245\n",
      "3/3 [==============================] - 7s 151ms/step - loss: 4.2360 - categorical_accuracy: 0.8471\n",
      "Epoch 2/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 5.5776 - categorical_accuracy: 0.5059\n",
      "Epoch 3/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.3993 - categorical_accuracy: 0.6000\n",
      "Epoch 4/245\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.4668 - categorical_accuracy: 0.8471\n",
      "Epoch 5/245\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.5325 - categorical_accuracy: 0.8118\n",
      "Epoch 6/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3355 - categorical_accuracy: 0.9412\n",
      "Epoch 7/245\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2463 - categorical_accuracy: 0.9412\n",
      "Epoch 8/245\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2274 - categorical_accuracy: 0.9412\n",
      "Epoch 9/245\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1875 - categorical_accuracy: 0.9294\n",
      "Epoch 10/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1338 - categorical_accuracy: 0.9529\n",
      "Epoch 11/245\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1034 - categorical_accuracy: 0.9529\n",
      "Epoch 12/245\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0904 - categorical_accuracy: 0.9529\n",
      "Epoch 13/245\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0815 - categorical_accuracy: 0.9765\n",
      "Epoch 14/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1253 - categorical_accuracy: 0.9412\n",
      "Epoch 15/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0807 - categorical_accuracy: 0.9765\n",
      "Epoch 16/245\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0746 - categorical_accuracy: 0.9647\n",
      "Epoch 17/245\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0727 - categorical_accuracy: 0.9765\n",
      "Epoch 18/245\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0409 - categorical_accuracy: 0.9882\n",
      "Epoch 19/245\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0496 - categorical_accuracy: 0.9882\n",
      "Epoch 20/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1018 - categorical_accuracy: 0.9765\n",
      "Epoch 21/245\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0479 - categorical_accuracy: 0.9765\n",
      "Epoch 22/245\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0923 - categorical_accuracy: 0.9647\n",
      "Epoch 23/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1064 - categorical_accuracy: 0.9765\n",
      "Epoch 24/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.9109 - categorical_accuracy: 0.8353\n",
      "Epoch 25/245\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 5.8663 - categorical_accuracy: 0.2941\n",
      "Epoch 26/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 2.6248 - categorical_accuracy: 0.3294\n",
      "Epoch 27/245\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 1.3034 - categorical_accuracy: 0.3529\n",
      "Epoch 28/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.1913 - categorical_accuracy: 0.3765\n",
      "Epoch 29/245\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.2323 - categorical_accuracy: 0.3647\n",
      "Epoch 30/245\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.0635 - categorical_accuracy: 0.3176\n",
      "Epoch 31/245\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.4134 - categorical_accuracy: 0.3647\n",
      "Epoch 32/245\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 6.7458 - categorical_accuracy: 0.3059\n",
      "Epoch 33/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 7.8558 - categorical_accuracy: 0.3529\n",
      "Epoch 34/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 6.3081 - categorical_accuracy: 0.3059\n",
      "Epoch 35/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 7.9828 - categorical_accuracy: 0.4235\n",
      "Epoch 36/245\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 25.6807 - categorical_accuracy: 0.3294\n",
      "Epoch 37/245\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 13.2802 - categorical_accuracy: 0.3294\n",
      "Epoch 38/245\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 4.2185 - categorical_accuracy: 0.3529\n",
      "Epoch 39/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.6977 - categorical_accuracy: 0.2471\n",
      "Epoch 40/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.0678 - categorical_accuracy: 0.5176\n",
      "Epoch 41/245\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.1106 - categorical_accuracy: 0.5294\n",
      "Epoch 42/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.7142 - categorical_accuracy: 0.7412\n",
      "Epoch 43/245\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5401 - categorical_accuracy: 0.7882\n",
      "Epoch 44/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.6627 - categorical_accuracy: 0.7529\n",
      "Epoch 45/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.5007 - categorical_accuracy: 0.7647\n",
      "Epoch 46/245\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.4446 - categorical_accuracy: 0.7412\n",
      "Epoch 47/245\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.4202 - categorical_accuracy: 0.7647\n",
      "Epoch 48/245\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.1106 - categorical_accuracy: 0.8353\n",
      "Epoch 49/245\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 9.0682 - categorical_accuracy: 0.8118\n",
      "Epoch 50/245\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.5603 - categorical_accuracy: 0.6353\n",
      "Epoch 51/245\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.6850 - categorical_accuracy: 0.5176\n",
      "Epoch 52/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.6719 - categorical_accuracy: 0.6118\n",
      "Epoch 53/245\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.6695 - categorical_accuracy: 0.6824\n",
      "Epoch 54/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.6472 - categorical_accuracy: 0.6824\n",
      "Epoch 55/245\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.6036 - categorical_accuracy: 0.7059\n",
      "Epoch 56/245\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.5483 - categorical_accuracy: 0.7412\n",
      "Epoch 57/245\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.4855 - categorical_accuracy: 0.8118\n",
      "Epoch 58/245\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.4436 - categorical_accuracy: 0.9294\n",
      "Epoch 59/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.4047 - categorical_accuracy: 0.9412\n",
      "Epoch 60/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3564 - categorical_accuracy: 0.9529\n",
      "Epoch 61/245\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3143 - categorical_accuracy: 0.9412\n",
      "Epoch 62/245\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1735 - categorical_accuracy: 0.9412\n",
      "Epoch 63/245\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2941 - categorical_accuracy: 0.9529\n",
      "Epoch 64/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3013 - categorical_accuracy: 0.9412\n",
      "Epoch 65/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2711 - categorical_accuracy: 0.9412\n",
      "Epoch 66/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2989 - categorical_accuracy: 0.9294\n",
      "Epoch 67/245\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2467 - categorical_accuracy: 0.9529\n",
      "Epoch 68/245\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2152 - categorical_accuracy: 0.9529\n",
      "Epoch 69/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2031 - categorical_accuracy: 0.9647\n",
      "Epoch 70/245\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1849 - categorical_accuracy: 0.9412\n",
      "Epoch 71/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1700 - categorical_accuracy: 0.9529\n",
      "Epoch 72/245\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1766 - categorical_accuracy: 0.9412\n",
      "Epoch 73/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1112 - categorical_accuracy: 0.9765\n",
      "Epoch 74/245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0966 - categorical_accuracy: 0.9647\n",
      "Epoch 75/245\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1256 - categorical_accuracy: 0.9647\n",
      "Epoch 76/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 4.6166 - categorical_accuracy: 0.6588\n",
      "Epoch 77/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 5.0999 - categorical_accuracy: 0.3529\n",
      "Epoch 78/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 2.2620 - categorical_accuracy: 0.3765\n",
      "Epoch 79/245\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.4092 - categorical_accuracy: 0.3647\n",
      "Epoch 80/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.8129 - categorical_accuracy: 0.6118\n",
      "Epoch 81/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.7032 - categorical_accuracy: 0.7294\n",
      "Epoch 82/245\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.6215 - categorical_accuracy: 0.7882\n",
      "Epoch 83/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.4326 - categorical_accuracy: 0.9059\n",
      "Epoch 84/245\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.4099 - categorical_accuracy: 0.8588\n",
      "Epoch 85/245\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3607 - categorical_accuracy: 0.9059\n",
      "Epoch 86/245\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2572 - categorical_accuracy: 0.9412\n",
      "Epoch 87/245\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2885 - categorical_accuracy: 0.8824\n",
      "Epoch 88/245\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2144 - categorical_accuracy: 0.9529\n",
      "Epoch 89/245\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2174 - categorical_accuracy: 0.9412\n",
      "Epoch 90/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1932 - categorical_accuracy: 0.9176\n",
      "Epoch 91/245\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2294 - categorical_accuracy: 0.9059\n",
      "Epoch 92/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1616 - categorical_accuracy: 0.9765\n",
      "Epoch 93/245\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1736 - categorical_accuracy: 0.9529\n",
      "Epoch 94/245\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1601 - categorical_accuracy: 0.9529\n",
      "Epoch 95/245\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0880 - categorical_accuracy: 0.9647\n",
      "Epoch 96/245\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0979 - categorical_accuracy: 0.9529\n",
      "Epoch 97/245\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0802 - categorical_accuracy: 0.9765\n",
      "Epoch 98/245\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1803 - categorical_accuracy: 0.9765\n",
      "Epoch 99/245\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1569 - categorical_accuracy: 0.9412\n",
      "Epoch 100/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0902 - categorical_accuracy: 0.9765\n",
      "Epoch 101/245\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0881 - categorical_accuracy: 0.9765\n",
      "Epoch 102/245\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.0863 - categorical_accuracy: 0.9765\n",
      "Epoch 103/245\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0602 - categorical_accuracy: 0.9765\n",
      "Epoch 104/245\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1320 - categorical_accuracy: 0.9765\n",
      "Epoch 105/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1306 - categorical_accuracy: 0.9412\n",
      "Epoch 106/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1096 - categorical_accuracy: 0.9647\n",
      "Epoch 107/245\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0804 - categorical_accuracy: 0.9647\n",
      "Epoch 108/245\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1791 - categorical_accuracy: 0.9176\n",
      "Epoch 109/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1999 - categorical_accuracy: 0.9412\n",
      "Epoch 110/245\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0796 - categorical_accuracy: 0.9647\n",
      "Epoch 111/245\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2519 - categorical_accuracy: 0.8588\n",
      "Epoch 112/245\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1129 - categorical_accuracy: 0.9765\n",
      "Epoch 113/245\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0923 - categorical_accuracy: 0.9882\n",
      "Epoch 114/245\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0854 - categorical_accuracy: 0.9765\n",
      "Epoch 115/245\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0888 - categorical_accuracy: 0.9765\n",
      "Epoch 116/245\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0627 - categorical_accuracy: 0.9882\n",
      "Epoch 117/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0912 - categorical_accuracy: 0.9529\n",
      "Epoch 118/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0770 - categorical_accuracy: 0.9765\n",
      "Epoch 119/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0721 - categorical_accuracy: 0.9765\n",
      "Epoch 120/245\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0724 - categorical_accuracy: 0.9765\n",
      "Epoch 121/245\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0691 - categorical_accuracy: 0.9765\n",
      "Epoch 122/245\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0516 - categorical_accuracy: 0.9882\n",
      "Epoch 123/245\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1092 - categorical_accuracy: 0.9529\n",
      "Epoch 124/245\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0528 - categorical_accuracy: 0.9882\n",
      "Epoch 125/245\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0979 - categorical_accuracy: 0.9647\n",
      "Epoch 126/245\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0587 - categorical_accuracy: 0.9765\n",
      "Epoch 127/245\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0733 - categorical_accuracy: 0.9765\n",
      "Epoch 128/245\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0566 - categorical_accuracy: 0.9882\n",
      "Epoch 129/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0578 - categorical_accuracy: 0.9882\n",
      "Epoch 130/245\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0500 - categorical_accuracy: 0.9882\n",
      "Epoch 131/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0495 - categorical_accuracy: 0.9882\n",
      "Epoch 132/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0479 - categorical_accuracy: 0.9882\n",
      "Epoch 133/245\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0457 - categorical_accuracy: 0.9882\n",
      "Epoch 134/245\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0473 - categorical_accuracy: 0.9765\n",
      "Epoch 135/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0480 - categorical_accuracy: 0.9765\n",
      "Epoch 136/245\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0453 - categorical_accuracy: 0.9882\n",
      "Epoch 137/245\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0575 - categorical_accuracy: 0.9647\n",
      "Epoch 138/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0443 - categorical_accuracy: 0.9882\n",
      "Epoch 139/245\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0473 - categorical_accuracy: 0.9882\n",
      "Epoch 140/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0382 - categorical_accuracy: 0.9882\n",
      "Epoch 141/245\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0799 - categorical_accuracy: 0.9765\n",
      "Epoch 142/245\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0428 - categorical_accuracy: 0.9765\n",
      "Epoch 143/245\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0485 - categorical_accuracy: 0.9882\n",
      "Epoch 144/245\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0523 - categorical_accuracy: 0.9882\n",
      "Epoch 145/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0433 - categorical_accuracy: 0.9882\n",
      "Epoch 146/245\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0698 - categorical_accuracy: 0.9765\n",
      "Epoch 147/245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0421 - categorical_accuracy: 0.9882\n",
      "Epoch 148/245\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0966 - categorical_accuracy: 0.9647\n",
      "Epoch 149/245\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0604 - categorical_accuracy: 0.9647\n",
      "Epoch 150/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0923 - categorical_accuracy: 0.9647\n",
      "Epoch 151/245\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1298 - categorical_accuracy: 0.9412\n",
      "Epoch 152/245\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0738 - categorical_accuracy: 0.9765\n",
      "Epoch 153/245\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1845 - categorical_accuracy: 0.9176\n",
      "Epoch 154/245\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1181 - categorical_accuracy: 0.9529\n",
      "Epoch 155/245\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0892 - categorical_accuracy: 0.9647\n",
      "Epoch 156/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0930 - categorical_accuracy: 0.9529\n",
      "Epoch 157/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0563 - categorical_accuracy: 0.9882\n",
      "Epoch 158/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0539 - categorical_accuracy: 0.9882\n",
      "Epoch 159/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0531 - categorical_accuracy: 0.9882\n",
      "Epoch 160/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0512 - categorical_accuracy: 0.9882\n",
      "Epoch 161/245\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0438 - categorical_accuracy: 0.9882\n",
      "Epoch 162/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0595 - categorical_accuracy: 0.9765\n",
      "Epoch 163/245\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0570 - categorical_accuracy: 0.9882\n",
      "Epoch 164/245\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0914 - categorical_accuracy: 0.9765\n",
      "Epoch 165/245\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0541 - categorical_accuracy: 0.9882\n",
      "Epoch 166/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0585 - categorical_accuracy: 0.9882\n",
      "Epoch 167/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0479 - categorical_accuracy: 0.9882\n",
      "Epoch 168/245\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0461 - categorical_accuracy: 0.9882\n",
      "Epoch 169/245\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0439 - categorical_accuracy: 0.9882\n",
      "Epoch 170/245\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0342 - categorical_accuracy: 0.9882\n",
      "Epoch 171/245\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0342 - categorical_accuracy: 0.9882\n",
      "Epoch 172/245\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0525 - categorical_accuracy: 0.9882\n",
      "Epoch 173/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0439 - categorical_accuracy: 0.9882\n",
      "Epoch 174/245\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0468 - categorical_accuracy: 0.9882\n",
      "Epoch 175/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0483 - categorical_accuracy: 0.9882\n",
      "Epoch 176/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0376 - categorical_accuracy: 0.9882\n",
      "Epoch 177/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0539 - categorical_accuracy: 0.9765\n",
      "Epoch 178/245\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0378 - categorical_accuracy: 0.9882\n",
      "Epoch 179/245\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0573 - categorical_accuracy: 0.9765\n",
      "Epoch 180/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0494 - categorical_accuracy: 0.9765\n",
      "Epoch 181/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1441 - categorical_accuracy: 0.9647\n",
      "Epoch 182/245\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0584 - categorical_accuracy: 0.9882\n",
      "Epoch 183/245\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0991 - categorical_accuracy: 0.9647\n",
      "Epoch 184/245\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1270 - categorical_accuracy: 0.9412\n",
      "Epoch 185/245\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0797 - categorical_accuracy: 0.9765\n",
      "Epoch 186/245\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1140 - categorical_accuracy: 0.9529\n",
      "Epoch 187/245\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0679 - categorical_accuracy: 0.9765\n",
      "Epoch 188/245\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0538 - categorical_accuracy: 0.9765\n",
      "Epoch 189/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0453 - categorical_accuracy: 0.9882\n",
      "Epoch 190/245\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0578 - categorical_accuracy: 0.9765\n",
      "Epoch 191/245\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0531 - categorical_accuracy: 0.9765\n",
      "Epoch 192/245\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0392 - categorical_accuracy: 0.9882\n",
      "Epoch 193/245\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0627 - categorical_accuracy: 0.9765\n",
      "Epoch 194/245\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0471 - categorical_accuracy: 0.9882\n",
      "Epoch 195/245\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0492 - categorical_accuracy: 0.9882\n",
      "Epoch 196/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0337 - categorical_accuracy: 0.9882\n",
      "Epoch 197/245\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0474 - categorical_accuracy: 0.9765\n",
      "Epoch 198/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0318 - categorical_accuracy: 0.9882\n",
      "Epoch 199/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0414 - categorical_accuracy: 0.9882\n",
      "Epoch 200/245\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0300 - categorical_accuracy: 0.9882\n",
      "Epoch 201/245\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0284 - categorical_accuracy: 0.9882\n",
      "Epoch 202/245\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0335 - categorical_accuracy: 0.9765\n",
      "Epoch 203/245\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0337 - categorical_accuracy: 0.9882\n",
      "Epoch 204/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0310 - categorical_accuracy: 0.9882\n",
      "Epoch 205/245\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0230 - categorical_accuracy: 0.9882\n",
      "Epoch 206/245\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0242 - categorical_accuracy: 0.9882\n",
      "Epoch 207/245\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0227 - categorical_accuracy: 0.9882\n",
      "Epoch 208/245\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0543 - categorical_accuracy: 0.9765\n",
      "Epoch 209/245\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0401 - categorical_accuracy: 0.9882\n",
      "Epoch 210/245\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0218 - categorical_accuracy: 0.9882\n",
      "Epoch 211/245\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0292 - categorical_accuracy: 0.9882\n",
      "Epoch 212/245\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0224 - categorical_accuracy: 0.9882\n",
      "Epoch 213/245\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0235 - categorical_accuracy: 0.9882\n",
      "Epoch 214/245\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0283 - categorical_accuracy: 0.9882\n",
      "Epoch 215/245\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0202 - categorical_accuracy: 0.9882\n",
      "Epoch 216/245\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0271 - categorical_accuracy: 0.9882\n",
      "Epoch 217/245\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0258 - categorical_accuracy: 0.9882\n",
      "Epoch 218/245\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0480 - categorical_accuracy: 0.9882\n",
      "Epoch 219/245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0673 - categorical_accuracy: 0.9765\n",
      "Epoch 220/245\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0257 - categorical_accuracy: 1.0000\n",
      "Epoch 221/245\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0641 - categorical_accuracy: 0.9765\n",
      "Epoch 222/245\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0951 - categorical_accuracy: 0.9647\n",
      "Epoch 223/245\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0481 - categorical_accuracy: 0.9882\n",
      "Epoch 224/245\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0841 - categorical_accuracy: 0.9765\n",
      "Epoch 225/245\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0401 - categorical_accuracy: 0.9882\n",
      "Epoch 226/245\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0792 - categorical_accuracy: 0.9765\n",
      "Epoch 227/245\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3420 - categorical_accuracy: 0.8471\n",
      "Epoch 228/245\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2075 - categorical_accuracy: 0.9647\n",
      "Epoch 229/245\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1782 - categorical_accuracy: 0.9529\n",
      "Epoch 230/245\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 4.4613 - categorical_accuracy: 0.7294\n",
      "Epoch 231/245\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2659 - categorical_accuracy: 0.9529\n",
      "Epoch 232/245\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.9682 - categorical_accuracy: 0.8353\n",
      "Epoch 233/245\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 2.0171 - categorical_accuracy: 0.4000\n",
      "Epoch 234/245\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.8909 - categorical_accuracy: 0.5529\n",
      "Epoch 235/245\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.9650 - categorical_accuracy: 0.5647\n",
      "Epoch 236/245\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 1.2977 - categorical_accuracy: 0.3765\n",
      "Epoch 237/245\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 1.4183 - categorical_accuracy: 0.3647\n",
      "Epoch 238/245\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 1.2458 - categorical_accuracy: 0.3059\n",
      "Epoch 239/245\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.3251 - categorical_accuracy: 0.3529\n",
      "Epoch 240/245\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 1.7306 - categorical_accuracy: 0.3176\n",
      "Epoch 241/245\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 1.3231 - categorical_accuracy: 0.4000\n",
      "Epoch 242/245\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 1.2184 - categorical_accuracy: 0.3176\n",
      "Epoch 243/245\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.1589 - categorical_accuracy: 0.3412\n",
      "Epoch 244/245\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.2339 - categorical_accuracy: 0.3765\n",
      "Epoch 245/245\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.0153 - categorical_accuracy: 0.5176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cc3d411f70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train , epochs = 245, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "banned-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "quantitative-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 313ms/step\n"
     ]
    }
   ],
   "source": [
    "res= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "proud-pocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2240144e-12, 3.1813145e-09, 1.0000000e+00],\n",
       "       [1.8118157e-12, 2.0148516e-09, 1.0000000e+00],\n",
       "       [2.1127683e-19, 1.0000000e+00, 6.0739567e-19],\n",
       "       [2.8947564e-14, 1.9281301e-09, 1.0000000e+00],\n",
       "       [2.1091804e-08, 9.9999988e-01, 8.5216030e-08]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "endless-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "flush-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "copyrighted-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "powerful-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "through-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "civilian-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = []\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "proper-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iloveyou'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "chronic-friendly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "(30, 1662)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "hello\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "iloveyou\n",
      "(30, 1662)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "iloveyou\n"
     ]
    }
   ],
   "source": [
    "cap = VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic : \n",
    "    while cap.isOpened() :\n",
    "\n",
    "        #Reading frames\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Make detection \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_styled_landmarks(image, results)\n",
    "        #print(results)\n",
    "        \n",
    "        #determining the result\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.insert(0, keypoints)\n",
    "        sequence = sequence[:30]\n",
    "        \n",
    "        if len(sequence) == 30 :\n",
    "            print(np.array(sequence).shape)\n",
    "            res= model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "\n",
    "            #SHOWING THE RESULTS\n",
    "\n",
    "            #checking if the value of the predicted action is greater than the threshold\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "\n",
    "                #checking if the sentence has more than word\n",
    "                if len(sentence) > 0: \n",
    "\n",
    "                    #if the predicted word doesn't match the last word, add it\n",
    "                    if actions[np.argmax(res)] != sentence[-1] : \n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                    #if the predicted word matches the last word \n",
    "                else : \n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "        #if the length of the sentence is greater than 5\n",
    "        if len(sentence) > 5 : \n",
    "\n",
    "            #reduce the array to the last five values\n",
    "            sentence = sentence[-5:]\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (640,40), (245,117,16) , -1)\n",
    "        cv2.putText(image, ' '.join(sentence) , (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1 , (255,255,255), 1,  cv2.LINE_AA)\n",
    "\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "\n",
    "        #break \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') : \n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acquired-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "favorite-holder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
